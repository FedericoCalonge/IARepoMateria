{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de clasificación con ANN: predice si una persona tiene diabetes o no.\n",
    "\n",
    "Ejemplo basado en el siguiente link: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen\n",
    "El objetivo de este algoritmo es poder predecir si una persona tiene diabetes o no. Para esto, se utiliza el conjunto de datos de diabetes de los indios Pima, el cual describe datos de registros médicos de los pacientes de los indios Pima y si tuvieron un inicio de diabetes dentro de los cinco años.\n",
    "\n",
    "El problema resulta ser de clasificación binaria, es decir, si el paciente tiene o no, diabetes (aparición de diabetes como 1 o no como 0). Todas las variables de entrada que describen a cada paciente son numéricas. Esto hace que sea fácil de usar directamente con redes neuronales que esperan valores numéricos de entrada y salida.\n",
    "El dataset se puede encontrar aquí:\n",
    "\n",
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
    "\n",
    "El objetivo es elegir un modelo y configuración de entrenamiento que logre la menor pérdida y la mayor precisión posible para un conjunto de datos dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['Number of times pregnant', 'Plasma glucose concentration', 'Diastolic blood pressure', 'Triceps skin fold thickness ', ' 2-Hour serum insulin ', ' Body mass index ', ' Diabetes pedigree function ',' Age', 'Class']\n",
    "\n",
    "dataset_diabetes = pd.read_csv(url, names=names, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skin fold thickness</th>\n",
       "      <th>2-Hour serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant  Plasma glucose concentration  \\\n",
       "0                         6                           148   \n",
       "1                         1                            85   \n",
       "2                         8                           183   \n",
       "3                         1                            89   \n",
       "4                         0                           137   \n",
       "5                         5                           116   \n",
       "6                         3                            78   \n",
       "7                        10                           115   \n",
       "8                         2                           197   \n",
       "9                         8                           125   \n",
       "\n",
       "   Diastolic blood pressure  Triceps skin fold thickness   \\\n",
       "0                        72                            35   \n",
       "1                        66                            29   \n",
       "2                        64                             0   \n",
       "3                        66                            23   \n",
       "4                        40                            35   \n",
       "5                        74                             0   \n",
       "6                        50                            32   \n",
       "7                         0                             0   \n",
       "8                        70                            45   \n",
       "9                        96                             0   \n",
       "\n",
       "    2-Hour serum insulin    Body mass index    Diabetes pedigree function   \\\n",
       "0                       0               33.6                         0.627   \n",
       "1                       0               26.6                         0.351   \n",
       "2                       0               23.3                         0.672   \n",
       "3                      94               28.1                         0.167   \n",
       "4                     168               43.1                         2.288   \n",
       "5                       0               25.6                         0.201   \n",
       "6                      88               31.0                         0.248   \n",
       "7                       0               35.3                         0.134   \n",
       "8                     543               30.5                         0.158   \n",
       "9                       0                0.0                         0.232   \n",
       "\n",
       "    Age  Class  \n",
       "0    50      1  \n",
       "1    31      0  \n",
       "2    32      1  \n",
       "3    21      0  \n",
       "4    33      1  \n",
       "5    30      0  \n",
       "6    26      1  \n",
       "7    29      0  \n",
       "8    53      1  \n",
       "9    54      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_diabetes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos al Dataset en las 8 entradas y una salida que será: 1 - Tiene Diabetes, 0 - No tiene diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset_diabetes[['Number of times pregnant', 'Plasma glucose concentration','Diastolic blood pressure', 'Triceps skin fold thickness ', ' 2-Hour serum insulin ', ' Body mass index ', ' Diabetes pedigree function ',' Age']]\n",
    "y = dataset_diabetes['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos en Keras se definen como una secuencia de capas (Sequential model). En base a esto, se van agregando distintas capas hasta que se completa el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo en Keras\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definido el modo Sequencial (Sequential model), hay que definir que la red será \"Fully-Conected\" y para esto se define la clase \"Dense\" o \"Dense Class\", la cual permite definir la cantidad de entradas que tendrá la red como así también las funciones de activación y otros parámetros.\n",
    "\n",
    "En la siguiente función se definen:\n",
    "\n",
    "a) Primer capa oculta con 12 nodos, 8 entradas y activación mediante función Relu.\n",
    "\n",
    "b) Segunda capa oculta con 8 nodos y función de activación Relu.\n",
    "\n",
    "c) Capa de salida tiene un solo nodoy usa la función de activación Sigmoide\n",
    "\n",
    "Resulta importante aclarar que la forma de la entrada al modelo se define como un argumento con la primera capa oculta. Esto significa que la línea de código que agrega la primera capa está haciendo 2 cosas, definiendo la entrada y la primera capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notar que después de la primera capa, no es necesario definir las entradas nuevamente para la próxima capa\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previamente a entrenar el modelo, debemos definir algunas herramientas:\n",
    "\n",
    "1) Función de pérdida: evalúa los pesos de la red a medida que se la va entrenando.\n",
    "\n",
    "2) Optimizador: El optimizador se utiliza para buscar diferentes pesos para la red. Pueden ser:\n",
    "SGD : Gradiente descendente\n",
    "\n",
    "3) Metrics: Una métrica es una función que se utiliza para juzgar el rendimiento de su modelo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epochs: Número fijo de iteraciones para entrenar a la red\n",
    "#### Bach: Número de filas del conjunto de datos que se consideran antes de que los pesos del modelo se actualicen dentro de cada Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que definimos el modelo, es hora de entrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 210us/step - loss: 7.1767 - accuracy: 0.4727\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 201us/step - loss: 1.3094 - accuracy: 0.6250\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 385us/step - loss: 1.0163 - accuracy: 0.6549\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.8995 - accuracy: 0.6536\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.8153 - accuracy: 0.6484\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.7721 - accuracy: 0.6615\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.7475 - accuracy: 0.6602\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.7114 - accuracy: 0.6654\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.6874 - accuracy: 0.6758\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.6641 - accuracy: 0.6771\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.6660 - accuracy: 0.6693\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.6368 - accuracy: 0.6693\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6271 - accuracy: 0.6745\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.6123 - accuracy: 0.6888\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.6309 - accuracy: 0.6680\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.6096 - accuracy: 0.6836\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6037 - accuracy: 0.6784\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 144us/step - loss: 0.5986 - accuracy: 0.6823\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.6019 - accuracy: 0.6810\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5785 - accuracy: 0.6888\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 200us/step - loss: 0.5930 - accuracy: 0.6849\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.5797 - accuracy: 0.7005\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 188us/step - loss: 0.5790 - accuracy: 0.7031\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5790 - accuracy: 0.6979\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5793 - accuracy: 0.6966\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5803 - accuracy: 0.6940\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.5724 - accuracy: 0.6940\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5743 - accuracy: 0.7122\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5806 - accuracy: 0.6901\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5730 - accuracy: 0.6953\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5752 - accuracy: 0.7044\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5704 - accuracy: 0.7083\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5754 - accuracy: 0.7031\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5671 - accuracy: 0.6966\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 157us/step - loss: 0.5818 - accuracy: 0.6940\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.5805 - accuracy: 0.7018\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.5785 - accuracy: 0.6901\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5688 - accuracy: 0.6992\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5643 - accuracy: 0.7044\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 155us/step - loss: 0.5676 - accuracy: 0.6849\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5637 - accuracy: 0.7109\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.5724 - accuracy: 0.6979\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5766 - accuracy: 0.7005\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5732 - accuracy: 0.6927\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5767 - accuracy: 0.7018\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5576 - accuracy: 0.7214\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5936 - accuracy: 0.6836\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5711 - accuracy: 0.6979\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5595 - accuracy: 0.7044\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5613 - accuracy: 0.7083\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5565 - accuracy: 0.7083\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 147us/step - loss: 0.5567 - accuracy: 0.7161\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 134us/step - loss: 0.5628 - accuracy: 0.6966\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5608 - accuracy: 0.7018\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5567 - accuracy: 0.6979\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5560 - accuracy: 0.7070\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.5601 - accuracy: 0.7057\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5687 - accuracy: 0.7044\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5507 - accuracy: 0.7135\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.5668 - accuracy: 0.7070\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5574 - accuracy: 0.7122\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5628 - accuracy: 0.7083\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.5585 - accuracy: 0.7083\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5526 - accuracy: 0.7148\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5636 - accuracy: 0.7135\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.5515 - accuracy: 0.7135\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5610 - accuracy: 0.7096\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5693 - accuracy: 0.6992\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5523 - accuracy: 0.7122\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5563 - accuracy: 0.7083\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.5559 - accuracy: 0.7122\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5629 - accuracy: 0.7057\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5624 - accuracy: 0.7057\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5603 - accuracy: 0.6901\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.5538 - accuracy: 0.7161\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5515 - accuracy: 0.7031\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5571 - accuracy: 0.7109\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5466 - accuracy: 0.7201\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.5632 - accuracy: 0.7057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5533 - accuracy: 0.7135\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.5556 - accuracy: 0.6992\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5562 - accuracy: 0.7070\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.5562 - accuracy: 0.7174\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5523 - accuracy: 0.7109\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.5461 - accuracy: 0.7070\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 158us/step - loss: 0.5464 - accuracy: 0.7122\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5642 - accuracy: 0.7174\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5532 - accuracy: 0.6966\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5485 - accuracy: 0.7070\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5688 - accuracy: 0.7148\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.5517 - accuracy: 0.6992\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5577 - accuracy: 0.7122\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.5479 - accuracy: 0.7083\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.5553 - accuracy: 0.7148\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5454 - accuracy: 0.7096\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5511 - accuracy: 0.7122\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.5461 - accuracy: 0.7201\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5482 - accuracy: 0.7148\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5723 - accuracy: 0.6953\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5563 - accuracy: 0.7044\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.5424 - accuracy: 0.7109\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5465 - accuracy: 0.7161\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.5478 - accuracy: 0.7096\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5460 - accuracy: 0.7122\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5421 - accuracy: 0.7057\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5420 - accuracy: 0.7018\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5430 - accuracy: 0.7122\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.5516 - accuracy: 0.7109\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5381 - accuracy: 0.7344\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5487 - accuracy: 0.7018\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5402 - accuracy: 0.7188\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5439 - accuracy: 0.7083\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5466 - accuracy: 0.7070\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5543 - accuracy: 0.7031\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5483 - accuracy: 0.7031\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5427 - accuracy: 0.7070\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.5520 - accuracy: 0.7148\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5427 - accuracy: 0.7188\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5670 - accuracy: 0.6914\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5471 - accuracy: 0.7174\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 82us/step - loss: 0.5385 - accuracy: 0.7135\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5471 - accuracy: 0.7135\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.5510 - accuracy: 0.7083\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5386 - accuracy: 0.7148\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5518 - accuracy: 0.7057\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.5379 - accuracy: 0.7266\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5433 - accuracy: 0.7070\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5421 - accuracy: 0.7083\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5355 - accuracy: 0.7201\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.5413 - accuracy: 0.7135\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.5410 - accuracy: 0.7227\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5416 - accuracy: 0.7135\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5597 - accuracy: 0.7031\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5398 - accuracy: 0.7135\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5484 - accuracy: 0.7135\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5360 - accuracy: 0.7174\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.5423 - accuracy: 0.7214\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.5418 - accuracy: 0.7174\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5358 - accuracy: 0.7201\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5419 - accuracy: 0.7148\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5374 - accuracy: 0.7135\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.5355 - accuracy: 0.7148\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5521 - accuracy: 0.7188\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5384 - accuracy: 0.7240\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5442 - accuracy: 0.7188\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5348 - accuracy: 0.7122\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5404 - accuracy: 0.7174\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5406 - accuracy: 0.7122\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.5297 - accuracy: 0.7214\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5401 - accuracy: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f874679e990>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar al modelo se usa la función evaluate(), la cual devuelve una lista con dos valores. La primera será la pérdida del modelo en el conjunto de datos y la segunda será la precisión del modelo en el conjunto de datos. Solo estamos interesados ​​en informar la precisión, por lo que ignoraremos el valor de la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 38us/step\n",
      "Accuracy: 71.88\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo entrenado a la red, conviene hacer predicciones para ver cómo está funcionando la Red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar predicciones, simplemente se usa la función predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7432973 ],\n",
       "       [0.1381226 ],\n",
       "       [0.84217095],\n",
       "       [0.3153587 ],\n",
       "       [0.3714774 ],\n",
       "       [0.30842873],\n",
       "       [0.3944246 ],\n",
       "       [0.7308627 ],\n",
       "       [0.9295894 ],\n",
       "       [0.26162633],\n",
       "       [0.1444375 ],\n",
       "       [0.8598991 ],\n",
       "       [0.43260005],\n",
       "       [0.98966986],\n",
       "       [0.4197957 ],\n",
       "       [0.29046065],\n",
       "       [0.628923  ],\n",
       "       [0.39837098],\n",
       "       [0.3714774 ],\n",
       "       [0.27375364],\n",
       "       [0.59392005],\n",
       "       [0.08295395],\n",
       "       [0.77396894],\n",
       "       [0.31994143],\n",
       "       [0.41901582],\n",
       "       [0.3714774 ],\n",
       "       [0.75983256],\n",
       "       [0.47869766],\n",
       "       [0.36543837],\n",
       "       [0.24596833],\n",
       "       [0.40979785],\n",
       "       [0.54403234],\n",
       "       [0.12552223],\n",
       "       [0.08230684],\n",
       "       [0.62804705],\n",
       "       [0.67274255],\n",
       "       [0.7522012 ],\n",
       "       [0.5746819 ],\n",
       "       [0.16226356],\n",
       "       [0.75826937],\n",
       "       [0.3714774 ],\n",
       "       [0.5598279 ],\n",
       "       [0.26079047],\n",
       "       [0.62811023],\n",
       "       [0.70506996],\n",
       "       [0.9528754 ],\n",
       "       [0.6665066 ],\n",
       "       [0.07744269],\n",
       "       [0.48072022],\n",
       "       [0.13943414],\n",
       "       [0.13666669],\n",
       "       [0.13569178],\n",
       "       [0.08547435],\n",
       "       [0.8102905 ],\n",
       "       [0.8530917 ],\n",
       "       [0.1771242 ],\n",
       "       [0.64967734],\n",
       "       [0.380062  ],\n",
       "       [0.50746703],\n",
       "       [0.3714774 ],\n",
       "       [0.13180925],\n",
       "       [0.70701045],\n",
       "       [0.07020194],\n",
       "       [0.3714774 ],\n",
       "       [0.5615946 ],\n",
       "       [0.22650093],\n",
       "       [0.10018888],\n",
       "       [0.14803635],\n",
       "       [0.09423473],\n",
       "       [0.18076618],\n",
       "       [0.22800055],\n",
       "       [0.37439048],\n",
       "       [0.47388178],\n",
       "       [0.46965945],\n",
       "       [0.05865312],\n",
       "       [0.26526007],\n",
       "       [0.02865149],\n",
       "       [0.232395  ],\n",
       "       [0.95805645],\n",
       "       [0.17907628],\n",
       "       [0.51396126],\n",
       "       [0.13485597],\n",
       "       [0.16968223],\n",
       "       [0.09706265],\n",
       "       [0.20925443],\n",
       "       [0.40634963],\n",
       "       [0.73869   ],\n",
       "       [0.12016863],\n",
       "       [0.3714774 ],\n",
       "       [0.13416271],\n",
       "       [0.15372324],\n",
       "       [0.50910485],\n",
       "       [0.08699618],\n",
       "       [0.31040114],\n",
       "       [0.09009679],\n",
       "       [0.6475489 ],\n",
       "       [0.17442499],\n",
       "       [0.3714774 ],\n",
       "       [0.2719258 ],\n",
       "       [0.5992848 ],\n",
       "       [0.68118936],\n",
       "       [0.6779394 ],\n",
       "       [0.03207552],\n",
       "       [0.06993067],\n",
       "       [0.2966725 ],\n",
       "       [0.3714774 ],\n",
       "       [0.00681663],\n",
       "       [0.40486392],\n",
       "       [0.09820773],\n",
       "       [0.03006834],\n",
       "       [0.3714774 ],\n",
       "       [0.94991744],\n",
       "       [0.06788125],\n",
       "       [0.2750032 ],\n",
       "       [0.49157462],\n",
       "       [0.5991759 ],\n",
       "       [0.5082477 ],\n",
       "       [0.5032834 ],\n",
       "       [0.25890017],\n",
       "       [0.0741707 ],\n",
       "       [0.3714774 ],\n",
       "       [0.34619027],\n",
       "       [0.2214127 ],\n",
       "       [0.07156905],\n",
       "       [0.12141003],\n",
       "       [0.3714774 ],\n",
       "       [0.3714774 ],\n",
       "       [0.3714774 ],\n",
       "       [0.3999164 ],\n",
       "       [0.1092463 ],\n",
       "       [0.3714774 ],\n",
       "       [0.7739193 ],\n",
       "       [0.38995495],\n",
       "       [0.43448135],\n",
       "       [0.11419849],\n",
       "       [0.38982216],\n",
       "       [0.08617628],\n",
       "       [0.29423758],\n",
       "       [0.17387219],\n",
       "       [0.78187954],\n",
       "       [0.40897405],\n",
       "       [0.2814417 ],\n",
       "       [0.31497613],\n",
       "       [0.31586683],\n",
       "       [0.3889032 ],\n",
       "       [0.09408363],\n",
       "       [0.18379894],\n",
       "       [0.42654127],\n",
       "       [0.33190414],\n",
       "       [0.10120763],\n",
       "       [0.46231103],\n",
       "       [0.45797583],\n",
       "       [0.37701163],\n",
       "       [0.4752553 ],\n",
       "       [0.90366197],\n",
       "       [0.48750642],\n",
       "       [0.35720375],\n",
       "       [0.44065928],\n",
       "       [0.07565606],\n",
       "       [0.3714774 ],\n",
       "       [0.21251693],\n",
       "       [0.4042055 ],\n",
       "       [0.5372181 ],\n",
       "       [0.16509052],\n",
       "       [0.14025833],\n",
       "       [0.6038037 ],\n",
       "       [0.6642083 ],\n",
       "       [0.48157936],\n",
       "       [0.40294084],\n",
       "       [0.08166851],\n",
       "       [0.29501167],\n",
       "       [0.3714774 ],\n",
       "       [0.5475958 ],\n",
       "       [0.14597097],\n",
       "       [0.1727001 ],\n",
       "       [0.3714774 ],\n",
       "       [0.07424027],\n",
       "       [0.3026793 ],\n",
       "       [0.723872  ],\n",
       "       [0.4968057 ],\n",
       "       [0.14647911],\n",
       "       [0.32959688],\n",
       "       [0.41968036],\n",
       "       [0.20556082],\n",
       "       [0.5177554 ],\n",
       "       [0.8892969 ],\n",
       "       [0.95756876],\n",
       "       [0.08654499],\n",
       "       [0.41792127],\n",
       "       [0.42618695],\n",
       "       [0.2464436 ],\n",
       "       [0.3714774 ],\n",
       "       [0.7903394 ],\n",
       "       [0.7834926 ],\n",
       "       [0.3006974 ],\n",
       "       [0.44955316],\n",
       "       [0.2197742 ],\n",
       "       [0.11335357],\n",
       "       [0.3875329 ],\n",
       "       [0.54393053],\n",
       "       [0.08146802],\n",
       "       [0.22880414],\n",
       "       [0.19646621],\n",
       "       [0.10388891],\n",
       "       [0.76544076],\n",
       "       [0.21765327],\n",
       "       [0.6767913 ],\n",
       "       [0.44301313],\n",
       "       [0.24938583],\n",
       "       [0.67379695],\n",
       "       [0.17056401],\n",
       "       [0.26372856],\n",
       "       [0.71012616],\n",
       "       [0.3714774 ],\n",
       "       [0.6256603 ],\n",
       "       [0.7780252 ],\n",
       "       [0.41822866],\n",
       "       [0.37905288],\n",
       "       [0.2460801 ],\n",
       "       [0.64267087],\n",
       "       [0.3714774 ],\n",
       "       [0.5333032 ],\n",
       "       [0.17098776],\n",
       "       [0.4878924 ],\n",
       "       [0.13200669],\n",
       "       [0.03932524],\n",
       "       [0.12146673],\n",
       "       [0.959302  ],\n",
       "       [0.7646936 ],\n",
       "       [0.0790723 ],\n",
       "       [0.5322637 ],\n",
       "       [0.89290845],\n",
       "       [0.06219067],\n",
       "       [0.4499142 ],\n",
       "       [0.10287599],\n",
       "       [0.9332348 ],\n",
       "       [0.40013745],\n",
       "       [0.6810196 ],\n",
       "       [0.58908886],\n",
       "       [0.08997423],\n",
       "       [0.1152183 ],\n",
       "       [0.21690151],\n",
       "       [0.7285098 ],\n",
       "       [0.58082587],\n",
       "       [0.42576233],\n",
       "       [0.8493524 ],\n",
       "       [0.64310145],\n",
       "       [0.5259552 ],\n",
       "       [0.8982008 ],\n",
       "       [0.0570766 ],\n",
       "       [0.22116621],\n",
       "       [0.14601728],\n",
       "       [0.07291768],\n",
       "       [0.09921902],\n",
       "       [0.88967   ],\n",
       "       [0.26209193],\n",
       "       [0.39508298],\n",
       "       [0.18296465],\n",
       "       [0.3714774 ],\n",
       "       [0.4112194 ],\n",
       "       [0.3714774 ],\n",
       "       [0.8789497 ],\n",
       "       [0.18069781],\n",
       "       [0.47467208],\n",
       "       [0.5888484 ],\n",
       "       [0.1431982 ],\n",
       "       [0.9531619 ],\n",
       "       [0.5875628 ],\n",
       "       [0.24523883],\n",
       "       [0.82286495],\n",
       "       [0.496556  ],\n",
       "       [0.17035276],\n",
       "       [0.30303848],\n",
       "       [0.10762477],\n",
       "       [0.03801214],\n",
       "       [0.15549171],\n",
       "       [0.4770825 ],\n",
       "       [0.40166807],\n",
       "       [0.14696848],\n",
       "       [0.5794734 ],\n",
       "       [0.52395844],\n",
       "       [0.3714774 ],\n",
       "       [0.40815392],\n",
       "       [0.6644639 ],\n",
       "       [0.24749272],\n",
       "       [0.40979344],\n",
       "       [0.85439426],\n",
       "       [0.5632273 ],\n",
       "       [0.17998134],\n",
       "       [0.2343911 ],\n",
       "       [0.03315871],\n",
       "       [0.23494016],\n",
       "       [0.48794612],\n",
       "       [0.3714774 ],\n",
       "       [0.14241154],\n",
       "       [0.3714774 ],\n",
       "       [0.6256253 ],\n",
       "       [0.5287247 ],\n",
       "       [0.80853724],\n",
       "       [0.06253644],\n",
       "       [0.9380462 ],\n",
       "       [0.3714774 ],\n",
       "       [0.09703203],\n",
       "       [0.18554588],\n",
       "       [0.392999  ],\n",
       "       [0.24260578],\n",
       "       [0.3714774 ],\n",
       "       [0.3714774 ],\n",
       "       [0.4393861 ],\n",
       "       [0.60295135],\n",
       "       [0.37096408],\n",
       "       [0.38364798],\n",
       "       [0.24372327],\n",
       "       [0.31559747],\n",
       "       [0.49338913],\n",
       "       [0.20341353],\n",
       "       [0.11952481],\n",
       "       [0.7394978 ],\n",
       "       [0.42729914],\n",
       "       [0.5661381 ],\n",
       "       [0.63172555],\n",
       "       [0.15650983],\n",
       "       [0.23476432],\n",
       "       [0.27894473],\n",
       "       [0.1334433 ],\n",
       "       [0.3714774 ],\n",
       "       [0.46928373],\n",
       "       [0.87296885],\n",
       "       [0.3714774 ],\n",
       "       [0.2270057 ],\n",
       "       [0.6870475 ],\n",
       "       [0.10766201],\n",
       "       [0.890381  ],\n",
       "       [0.19398987],\n",
       "       [0.15123364],\n",
       "       [0.3714774 ],\n",
       "       [0.12501591],\n",
       "       [0.50503105],\n",
       "       [0.46910033],\n",
       "       [0.77102274],\n",
       "       [0.2991846 ],\n",
       "       [0.20844299],\n",
       "       [0.29609635],\n",
       "       [0.2816226 ],\n",
       "       [0.0185792 ],\n",
       "       [0.31561315],\n",
       "       [0.3714774 ],\n",
       "       [0.6949928 ],\n",
       "       [0.24234359],\n",
       "       [0.2992743 ],\n",
       "       [0.21757963],\n",
       "       [0.26625   ],\n",
       "       [0.09946132],\n",
       "       [0.08734835],\n",
       "       [0.15546507],\n",
       "       [0.75764865],\n",
       "       [0.43753836],\n",
       "       [0.37648973],\n",
       "       [0.17796656],\n",
       "       [0.3714774 ],\n",
       "       [0.44537506],\n",
       "       [0.38717458],\n",
       "       [0.18821247],\n",
       "       [0.2931601 ],\n",
       "       [0.5459699 ],\n",
       "       [0.32503605],\n",
       "       [0.42328689],\n",
       "       [0.09990498],\n",
       "       [0.0700116 ],\n",
       "       [0.3714774 ],\n",
       "       [0.46120313],\n",
       "       [0.4015737 ],\n",
       "       [0.11614537],\n",
       "       [0.3714774 ],\n",
       "       [0.42071036],\n",
       "       [0.9256083 ],\n",
       "       [0.11631429],\n",
       "       [0.2588923 ],\n",
       "       [0.8027901 ],\n",
       "       [0.07436935],\n",
       "       [0.19403411],\n",
       "       [0.08242487],\n",
       "       [0.4219527 ],\n",
       "       [0.17154832],\n",
       "       [0.34008744],\n",
       "       [0.14296421],\n",
       "       [0.36459854],\n",
       "       [0.25383425],\n",
       "       [0.8399631 ],\n",
       "       [0.206995  ],\n",
       "       [0.69651157],\n",
       "       [0.8997568 ],\n",
       "       [0.56158614],\n",
       "       [0.26229885],\n",
       "       [0.511224  ],\n",
       "       [0.5159641 ],\n",
       "       [0.45371088],\n",
       "       [0.35362813],\n",
       "       [0.13168415],\n",
       "       [0.92833996],\n",
       "       [0.3727994 ],\n",
       "       [0.34396577],\n",
       "       [0.2118023 ],\n",
       "       [0.1781032 ],\n",
       "       [0.71879673],\n",
       "       [0.3714774 ],\n",
       "       [0.5300203 ],\n",
       "       [0.16752528],\n",
       "       [0.87776214],\n",
       "       [0.5570061 ],\n",
       "       [0.1239633 ],\n",
       "       [0.51908076],\n",
       "       [0.3714774 ],\n",
       "       [0.16079108],\n",
       "       [0.3714774 ],\n",
       "       [0.3767576 ],\n",
       "       [0.13212012],\n",
       "       [0.3831103 ],\n",
       "       [0.11640225],\n",
       "       [0.37387607],\n",
       "       [0.43657127],\n",
       "       [0.16232607],\n",
       "       [0.3714774 ],\n",
       "       [0.265926  ],\n",
       "       [0.5271274 ],\n",
       "       [0.47701323],\n",
       "       [0.1255813 ],\n",
       "       [0.3714774 ],\n",
       "       [0.3714774 ],\n",
       "       [0.65839416],\n",
       "       [0.47082934],\n",
       "       [0.18772519],\n",
       "       [0.07231123],\n",
       "       [0.26224035],\n",
       "       [0.23601204],\n",
       "       [0.94333494],\n",
       "       [0.6866567 ],\n",
       "       [0.45731956],\n",
       "       [0.07309262],\n",
       "       [0.25835845],\n",
       "       [0.17242104],\n",
       "       [0.0936294 ],\n",
       "       [0.3714774 ],\n",
       "       [0.5887332 ],\n",
       "       [0.44427225],\n",
       "       [0.9288132 ],\n",
       "       [0.13602136],\n",
       "       [0.22038186],\n",
       "       [0.21917057],\n",
       "       [0.08833352],\n",
       "       [0.3714774 ],\n",
       "       [0.31865415],\n",
       "       [0.5554182 ],\n",
       "       [0.02094919],\n",
       "       [0.3714774 ],\n",
       "       [0.88880986],\n",
       "       [0.19833897],\n",
       "       [0.1783722 ],\n",
       "       [0.73269814],\n",
       "       [0.15775436],\n",
       "       [0.26374194],\n",
       "       [0.1321371 ],\n",
       "       [0.17430429],\n",
       "       [0.18843469],\n",
       "       [0.27838314],\n",
       "       [0.3714774 ],\n",
       "       [0.08957706],\n",
       "       [0.33913615],\n",
       "       [0.20362654],\n",
       "       [0.3714774 ],\n",
       "       [0.2475472 ],\n",
       "       [0.30835742],\n",
       "       [0.3645577 ],\n",
       "       [0.5399475 ],\n",
       "       [0.34390524],\n",
       "       [0.34185374],\n",
       "       [0.6458328 ],\n",
       "       [0.32978347],\n",
       "       [0.31424153],\n",
       "       [0.5235634 ],\n",
       "       [0.61763316],\n",
       "       [0.06811798],\n",
       "       [0.16040194],\n",
       "       [0.44113496],\n",
       "       [0.94702816],\n",
       "       [0.40909544],\n",
       "       [0.46140406],\n",
       "       [0.624046  ],\n",
       "       [0.18851306],\n",
       "       [0.5445276 ],\n",
       "       [0.13905568],\n",
       "       [0.09734552],\n",
       "       [0.26293233],\n",
       "       [0.3714774 ],\n",
       "       [0.12776193],\n",
       "       [0.38855708],\n",
       "       [0.37301755],\n",
       "       [0.13309832],\n",
       "       [0.3714774 ],\n",
       "       [0.5410615 ],\n",
       "       [0.07079566],\n",
       "       [0.15082683],\n",
       "       [0.5452611 ],\n",
       "       [0.2640045 ],\n",
       "       [0.20992719],\n",
       "       [0.03254826],\n",
       "       [0.11979011],\n",
       "       [0.3714774 ],\n",
       "       [0.28918785],\n",
       "       [0.04236696],\n",
       "       [0.37447673],\n",
       "       [0.40172493],\n",
       "       [0.02054755],\n",
       "       [0.20514563],\n",
       "       [0.3063339 ],\n",
       "       [0.3714774 ],\n",
       "       [0.48899707],\n",
       "       [0.43214506],\n",
       "       [0.01963698],\n",
       "       [0.8844312 ],\n",
       "       [0.2054582 ],\n",
       "       [0.39676654],\n",
       "       [0.12530258],\n",
       "       [0.69899493],\n",
       "       [0.5631169 ],\n",
       "       [0.16755092],\n",
       "       [0.26047298],\n",
       "       [0.22061867],\n",
       "       [0.4799292 ],\n",
       "       [0.24872427],\n",
       "       [0.3714774 ],\n",
       "       [0.22298452],\n",
       "       [0.22831659],\n",
       "       [0.20591916],\n",
       "       [0.18975559],\n",
       "       [0.93613434],\n",
       "       [0.13363764],\n",
       "       [0.0350332 ],\n",
       "       [0.47982633],\n",
       "       [0.4915936 ],\n",
       "       [0.8113592 ],\n",
       "       [0.5172547 ],\n",
       "       [0.2757267 ],\n",
       "       [0.0388    ],\n",
       "       [0.1549151 ],\n",
       "       [0.54408026],\n",
       "       [0.4343237 ],\n",
       "       [0.42916754],\n",
       "       [0.22733165],\n",
       "       [0.16677049],\n",
       "       [0.11355454],\n",
       "       [0.41287002],\n",
       "       [0.03703776],\n",
       "       [0.10433953],\n",
       "       [0.40178767],\n",
       "       [0.70128405],\n",
       "       [0.15234473],\n",
       "       [0.05227393],\n",
       "       [0.76321334],\n",
       "       [0.1049829 ],\n",
       "       [0.34704056],\n",
       "       [0.3714774 ],\n",
       "       [0.17036764],\n",
       "       [0.18119343],\n",
       "       [0.08878028],\n",
       "       [0.28487214],\n",
       "       [0.04963702],\n",
       "       [0.5721006 ],\n",
       "       [0.3714774 ],\n",
       "       [0.50459665],\n",
       "       [0.0935109 ],\n",
       "       [0.04949241],\n",
       "       [0.16641599],\n",
       "       [0.3714774 ],\n",
       "       [0.48729432],\n",
       "       [0.3714774 ],\n",
       "       [0.43796143],\n",
       "       [0.31117943],\n",
       "       [0.7539605 ],\n",
       "       [0.76784396],\n",
       "       [0.2642096 ],\n",
       "       [0.39288512],\n",
       "       [0.13124764],\n",
       "       [0.21114177],\n",
       "       [0.98346704],\n",
       "       [0.18789329],\n",
       "       [0.72767293],\n",
       "       [0.385714  ],\n",
       "       [0.3714774 ],\n",
       "       [0.14251697],\n",
       "       [0.6842194 ],\n",
       "       [0.43230698],\n",
       "       [0.46130702],\n",
       "       [0.45391172],\n",
       "       [0.71040154],\n",
       "       [0.3714774 ],\n",
       "       [0.01869896],\n",
       "       [0.3864166 ],\n",
       "       [0.5911831 ],\n",
       "       [0.39974713],\n",
       "       [0.04998714],\n",
       "       [0.25931293],\n",
       "       [0.14326626],\n",
       "       [0.3714774 ],\n",
       "       [0.8292459 ],\n",
       "       [0.55550456],\n",
       "       [0.3714774 ],\n",
       "       [0.15728597],\n",
       "       [0.4443398 ],\n",
       "       [0.49369624],\n",
       "       [0.4513631 ],\n",
       "       [0.3714774 ],\n",
       "       [0.75557524],\n",
       "       [0.21030709],\n",
       "       [0.46824494],\n",
       "       [0.2016816 ],\n",
       "       [0.13854681],\n",
       "       [0.06749073],\n",
       "       [0.6281787 ],\n",
       "       [0.84843993],\n",
       "       [0.52394533],\n",
       "       [0.13515161],\n",
       "       [0.7410328 ],\n",
       "       [0.3714774 ],\n",
       "       [0.23267491],\n",
       "       [0.09194488],\n",
       "       [0.16076872],\n",
       "       [0.19918036],\n",
       "       [0.5293866 ],\n",
       "       [0.1626691 ],\n",
       "       [0.62972456],\n",
       "       [0.19854993],\n",
       "       [0.29203272],\n",
       "       [0.45242435],\n",
       "       [0.3799884 ],\n",
       "       [0.33397895],\n",
       "       [0.2557726 ],\n",
       "       [0.08871661],\n",
       "       [0.20553342],\n",
       "       [0.08997251],\n",
       "       [0.25349408],\n",
       "       [0.41240698],\n",
       "       [0.6533767 ],\n",
       "       [0.201587  ],\n",
       "       [0.52914166],\n",
       "       [0.5856728 ],\n",
       "       [0.3714774 ],\n",
       "       [0.3714774 ],\n",
       "       [0.38439146],\n",
       "       [0.15316023],\n",
       "       [0.40310147],\n",
       "       [0.3714774 ],\n",
       "       [0.19549777],\n",
       "       [0.48467693],\n",
       "       [0.38926476],\n",
       "       [0.53786653],\n",
       "       [0.39758894],\n",
       "       [0.6245843 ],\n",
       "       [0.17221065],\n",
       "       [0.12816577],\n",
       "       [0.70482427],\n",
       "       [0.96614724],\n",
       "       [0.61249286],\n",
       "       [0.38049778],\n",
       "       [0.6229265 ],\n",
       "       [0.45720026],\n",
       "       [0.42355677],\n",
       "       [0.61697364],\n",
       "       [0.74976826],\n",
       "       [0.3473686 ],\n",
       "       [0.40627673],\n",
       "       [0.20012581],\n",
       "       [0.04955732],\n",
       "       [0.3714774 ],\n",
       "       [0.01129218],\n",
       "       [0.9157053 ],\n",
       "       [0.6905078 ],\n",
       "       [0.22799118],\n",
       "       [0.7432146 ],\n",
       "       [0.6386727 ],\n",
       "       [0.18380769],\n",
       "       [0.81030333],\n",
       "       [0.3714774 ],\n",
       "       [0.26275384],\n",
       "       [0.11733167],\n",
       "       [0.4897693 ],\n",
       "       [0.32332373],\n",
       "       [0.39087892],\n",
       "       [0.469538  ],\n",
       "       [0.48873   ],\n",
       "       [0.39769706],\n",
       "       [0.57294774],\n",
       "       [0.3714774 ],\n",
       "       [0.41030553],\n",
       "       [0.21217774],\n",
       "       [0.92470354],\n",
       "       [0.3714774 ],\n",
       "       [0.6057468 ],\n",
       "       [0.38565612],\n",
       "       [0.55669993],\n",
       "       [0.5126759 ],\n",
       "       [0.5219757 ],\n",
       "       [0.46988568],\n",
       "       [0.33414778],\n",
       "       [0.21899153],\n",
       "       [0.15087388],\n",
       "       [0.12908864],\n",
       "       [0.41074136],\n",
       "       [0.7940193 ],\n",
       "       [0.49158263],\n",
       "       [0.40232632],\n",
       "       [0.14269032],\n",
       "       [0.8285176 ],\n",
       "       [0.38394922],\n",
       "       [0.23040155],\n",
       "       [0.5300933 ],\n",
       "       [0.3714774 ],\n",
       "       [0.07334785],\n",
       "       [0.5153775 ],\n",
       "       [0.4364374 ],\n",
       "       [0.10400919],\n",
       "       [0.42491984],\n",
       "       [0.3714774 ],\n",
       "       [0.23584613],\n",
       "       [0.14779057],\n",
       "       [0.28595638],\n",
       "       [0.50497   ],\n",
       "       [0.12887043],\n",
       "       [0.25243822],\n",
       "       [0.32311118],\n",
       "       [0.17137153],\n",
       "       [0.22638017],\n",
       "       [0.3714774 ],\n",
       "       [0.47892982],\n",
       "       [0.23709163],\n",
       "       [0.33271948],\n",
       "       [0.2953224 ],\n",
       "       [0.13465458],\n",
       "       [0.38079944],\n",
       "       [0.33980313],\n",
       "       [0.5524884 ],\n",
       "       [0.3714774 ],\n",
       "       [0.3714774 ],\n",
       "       [0.5810732 ],\n",
       "       [0.3714774 ],\n",
       "       [0.43516392],\n",
       "       [0.22810487],\n",
       "       [0.11092138],\n",
       "       [0.3714774 ],\n",
       "       [0.49913758],\n",
       "       [0.53198516],\n",
       "       [0.12853612],\n",
       "       [0.2420901 ],\n",
       "       [0.3714774 ],\n",
       "       [0.70117885],\n",
       "       [0.28877628],\n",
       "       [0.31078568],\n",
       "       [0.4692708 ],\n",
       "       [0.16061042],\n",
       "       [0.6735019 ],\n",
       "       [0.08776936],\n",
       "       [0.8655019 ],\n",
       "       [0.30411977],\n",
       "       [0.8049418 ],\n",
       "       [0.2499486 ],\n",
       "       [0.36264756],\n",
       "       [0.41692466],\n",
       "       [0.09403575]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza predicciones de probabilidades\n",
    "predictions = model.predict(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza predicciones por clases\n",
    "predictions = model.predict_classes(X)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
